{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalLayer",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/8LjI8+WpNYFy7TWfbT08",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavi-ninjaac/NuralNetwork_scratch/blob/main/CNN/ConvolutionalLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IpwmtBke1F9"
      },
      "source": [
        "# conolutional layer\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUignDQe8Vv"
      },
      "source": [
        "class con2D:\r\n",
        "  def __init__(self, filter , kernal_size, img_channel,strides = (1,1) ):\r\n",
        "    self.filter = None\r\n",
        "    self.bias = None\r\n",
        "    \"\"\"Convolute the image with the filter and strids\"\"\"\r\n",
        "    \r\n",
        "    \r\n",
        "    f_channel = img_channel               #filter channel must match with the image channel\r\n",
        "    self.no_filters = filter                   # number of filters\r\n",
        "    f_dim , _ = kernal_size\r\n",
        "    self.f_dim =  f_dim              # get the filter size\r\n",
        "    self.s , _ = strides\r\n",
        "    f_size = (self.no_filters , f_channel , f_dim , f_dim) # get the strides dimentions\r\n",
        "\r\n",
        "    #initialize the filter\r\n",
        "    \"\"\" Initalize the filter with the noraml distribution with the standard deviation inversely proportional the square root of the number of units\"\"\"\r\n",
        "    sdv = 1.0 / np.sqrt(np.prod(f_size))\r\n",
        "    #self.filter = np.random.normal(loc = 0, scale = sdv, size = f_size)\r\n",
        "    self.filter = np.array([[[1,0,1] , [2,1,1] , [0,1,2]]])\r\n",
        "    self.bias = np.zeros((self.no_filters , 1)) # each for the one filters    \r\n",
        "\r\n",
        "  \r\n",
        "  #forward propogaton\r\n",
        "  def forward_propogation(self, image):\r\n",
        "    print(image.shape)\r\n",
        "    (img_channel , input_dim , _ ) = image.shape #input dimensions channel first dimention \r\n",
        "    \r\n",
        "    #calculate the output dimension, so according to that i can create the empty array to store value\r\n",
        "    out_dim = int(((input_dim - self.f_dim) / self.s) + 1)\r\n",
        "    print('out put dimention',out_dim)\r\n",
        "    #create the empty array with output dimetions\r\n",
        "    self.output = np.zeros((1 , out_dim, out_dim )) #syntax np.zeros(channel , row , col)\r\n",
        "    for curr_filter in range(self.no_filters): # for loop over the number of filters\r\n",
        "      curr_y = out_y =0\r\n",
        "      \r\n",
        "      #move vertically over the image\r\n",
        "      while (curr_y + self.f_dim) <= input_dim:\r\n",
        "        curr_x = out_x = 0\r\n",
        "        #move horizondally\r\n",
        "        while (curr_x + self.f_dim) <= input_dim:\r\n",
        "          \r\n",
        "          \"\"\"perform convolution operation on the image\"\"\"\r\n",
        "          self.output[curr_filter , curr_y , curr_x] = np.sum(self.filter[curr_filter] * image[: , curr_y : curr_y + self.f_dim , curr_x : curr_x + self.f_dim]) #+ self.bias[curr_filter]\r\n",
        "\r\n",
        "          curr_x += self.s\r\n",
        "          out_x +=1\r\n",
        "        curr_y += self.s\r\n",
        "        out_y += 1\r\n",
        "    print(self.output)\r\n",
        "    return self.output\r\n",
        "\r\n",
        "    def back_propogation(self):\r\n",
        "      pass\r\n",
        "\r\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVoaFlOtZHF6"
      },
      "source": [
        "class MaxPooling2D(con2D):\r\n",
        "  def __init__(self , pool_size = 1, strides=1):\r\n",
        "    self.pool_size = pool_size #getting the kernal size for pooling the layer out\r\n",
        "    self.strides = strides\r\n",
        "    \r\n",
        "  def forward_propogation(self , image):\r\n",
        "\r\n",
        "    \"\"\" downsample of the image using the kernal size and strides\"\"\"\r\n",
        "    img_channel , h_prev , w_prev  = image.shape    # shape of the image\r\n",
        "    # calculate output dimensions after the maxpooling operation.\r\n",
        "    h = int((h_prev - self.pool_size)/self.strides)+1 \r\n",
        "    w = int((w_prev - self.pool_size)/self.strides)+1\r\n",
        "    \r\n",
        "    # create a matrix to hold the values of the maxpooling operation.\r\n",
        "    self.output = np.zeros((img_channel, h, w))\r\n",
        "    # slide the window over every part of the image using stride s. Take the maximum value at each step.\r\n",
        "    for i in range(img_channel):\r\n",
        "        curr_y = out_y = 0\r\n",
        "        # slide the max pooling window vertically across the image\r\n",
        "        while curr_y + self.pool_size <= h_prev:\r\n",
        "            curr_x = out_x = 0\r\n",
        "            # slide the max pooling window horizontally across the image\r\n",
        "            while curr_x + self.pool_size <= w_prev:\r\n",
        "                # choose the maximum value within the window at each step and store it to the output matrix\r\n",
        "                self.output[i, out_y, out_x] = np.max(image[i, curr_y:curr_y+self.pool_size, curr_x:curr_x+self.pool_size])\r\n",
        "                curr_x += self.strides\r\n",
        "                out_x += 1\r\n",
        "            curr_y += self.strides\r\n",
        "            out_y += 1\r\n",
        "    return self.output\r\n",
        "\r\n",
        "    def back_propogation(self):\r\n",
        "      pass\r\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKZCutOkcabM"
      },
      "source": [
        "class Flatten(con2D):\r\n",
        "  \"\"\" get the strignt single channel fully connet layer \"\"\"\r\n",
        "  def __init__(self):\r\n",
        "    self.flatten_image = None\r\n",
        "    \r\n",
        "  def forward_propogation(self , image):\r\n",
        "    image_channel , input_dim , _ = image.shape\r\n",
        "    self.flatten_image = image.reshape((image_channel * input_dim * input_dim , 1)) \r\n",
        "    return self.flatten_image \r\n",
        "\r\n",
        "  def back_propogation(self):\r\n",
        "      pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ4RKj2mdaGF"
      },
      "source": [
        "class FClayer:\r\n",
        "  def __init__(self , input_size , output_size):\r\n",
        "    self.input = None\r\n",
        "    self.output = None\r\n",
        "    # initialize the weights using the normal distribution\r\n",
        "    self.weights = np.random.rand(input_size , output_size) - 0.5\r\n",
        "    self.bias =  np.random.rand(1,output_size) - 0.5 \r\n",
        "\r\n",
        "  def forward_propogation(self , input):\r\n",
        "    self.input = input\r\n",
        "    self.output = np.dot(self.input , self.weights) + self.bias\r\n",
        "    return self.output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je7KVBmaF8oC"
      },
      "source": [
        "class network:\r\n",
        "  def __init__(self):\r\n",
        "    self.layers = []\r\n",
        "\r\n",
        "  #add the layer in the model\r\n",
        "  def add(self , layer):\r\n",
        "    self.layers.append(layer)\r\n",
        "\r\n",
        "  def fit(self , x_train ,  y_train , epoches):\r\n",
        "    sampels = len(x_train)\r\n",
        "    #loop over for epoches\r\n",
        "    for i in range(epoches):\r\n",
        "      \r\n",
        "      for j in range(sampels):\r\n",
        "        output = x_train[j] \r\n",
        "        for layer in self.layers:\r\n",
        "          print(layer)\r\n",
        "          output = layer.forward_propogation(output)\r\n",
        "    print(output)\r\n",
        "\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtEJ1g6OHtBm"
      },
      "source": [
        "model = network()\r\n",
        "model.add(con2D(filter = 1 , kernal_size =(3,3) , strides = (1,1) , img_channel =1))\r\n",
        "model.add(MaxPooling2D(pool_size = 2))\r\n",
        "model.add(Flatten())"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAc1cZ1GMI70",
        "outputId": "35c8af4e-3417-4bb9-e31f-79eac9bd5528"
      },
      "source": [
        "i = np.array([[[[1,2,1,0,1] , [2,1,1,2,1] , [3,2,1,0,0] , [0,1,2,3,1] , [2,1,1,0,2]]]])\r\n",
        "print(i.shape)\r\n",
        "model.fit(i ,0 ,1)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 5, 5)\n",
            "<__main__.con2D object at 0x7f37e7f89f10>\n",
            "(1, 5, 5)\n",
            "out put dimention 3\n",
            "[[[12.  8.  7.]\n",
            "  [17. 16.  9.]\n",
            "  [10. 10. 13.]]]\n",
            "<__main__.MaxPooling2D object at 0x7f37e7f89e50>\n",
            "<__main__.Flatten object at 0x7f37e7f894d0>\n",
            "[[17.]\n",
            " [16.]\n",
            " [17.]\n",
            " [16.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM_PPS7JkOmW",
        "outputId": "a5cb7a5e-cba9-4731-f7c3-6b54aa1f2eaa"
      },
      "source": [
        "f_size = (2,3,3)\r\n",
        "sdv = 1.0 / np.sqrt(np.prod(f_size))\r\n",
        "sd = np.random.normal(loc = 0, scale = sdv, size = f_size)\r\n",
        "sd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.2358713 ,  0.26419976, -0.05489258],\n",
              "        [-0.07005125, -0.03529608, -0.13862036],\n",
              "        [-0.42406881,  0.16785173, -0.26264137]],\n",
              "\n",
              "       [[ 0.27956213,  0.14691208,  0.31053885],\n",
              "        [-0.21537503,  0.16352159,  0.0658891 ],\n",
              "        [-0.65043857,  0.19225158,  0.08999125]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpvgvIc-kQrb",
        "outputId": "aa3a996f-9fe3-4abe-ae3c-eb66eb22c8f2"
      },
      "source": [
        "s = np.array([[[1,0,1] , [2,1,1] , [0,1,2]]])\r\n",
        "s"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 0, 1],\n",
              "        [2, 1, 1],\n",
              "        [0, 1, 2]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHIigI3DugQ7"
      },
      "source": [
        "i = np.array([ [[1,2,1,0,1] , [2,1,1,2,1] , [3,2,1,0,0] , [0,1,2,3,1] , [2,1,1,0,2]]])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg5WFQJ3LmR_",
        "outputId": "308c4a0b-3a85-4a15-d1e2-8ff9708fcbaf"
      },
      "source": [
        "i.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi8081s7Ln_6",
        "outputId": "d03692f7-61f9-4f99-ba3e-c01154ec37e5"
      },
      "source": [
        "np.zeros((1,5,5))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82kVP018SC0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}