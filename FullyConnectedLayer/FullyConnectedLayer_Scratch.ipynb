{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FullyConnectedLayer_Scratch",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM60r4UiheSwh9IduhGSbXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavi-ninjaac/NuralNetwork_scratch/blob/main/FullyConnectedLayer/FullyConnectedLayer_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvU7DvCCReTN"
      },
      "source": [
        "#gonna train the XOR gate from scratch\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E--1Eqb-RsUT"
      },
      "source": [
        "class FClayer:\n",
        "  def __init__(self , input_size , output_size):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "    #rondomly initialize the weights\n",
        "    self.weights = np.random.rand(input_size , output_size) - 0.5\n",
        "    self.bias =  np.random.rand(1,output_size) - 0.5 \n",
        "\n",
        "  def forward_propogation(self , input):\n",
        "    self.input = input\n",
        "    #print('weights',self.weights)\n",
        "    #print('bias',self.bias)\n",
        "    self.output = np.dot(self.input , self.weights) + self.bias\n",
        "    return self.output\n",
        "\n",
        "  def back_propogation(self , output_error , learning_rate):\n",
        "    input_error = np.dot(output_error , self.weights.T)\n",
        "    #print('back weight' , self.weights)\n",
        "    weights_error = np.dot(self.input.T , output_error)\n",
        "    bias_error = output_error\n",
        "    #update the weights and bias\n",
        "    self.weights -= learning_rate *  weights_error\n",
        "    self.bias -= learning_rate * bias_error\n",
        "\n",
        "    return input_error"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo6_1e9dULiX"
      },
      "source": [
        "#activation layer\n",
        "#inherite the fully connected layer\n",
        "\n",
        "\n",
        "\n",
        "class ActivationLayer(FClayer):\n",
        "  def __init__(self, actvation , activation_derivated):\n",
        "    self.actvation = actvation\n",
        "    self.activation_derivated = activation_derivated\n",
        "\n",
        "  def forward_propogation(self , input_data):\n",
        "    self.input = input_data\n",
        "    self.output = self.actvation(self.input)\n",
        "    print('activation' , self.output)\n",
        "    return self.output\n",
        "\n",
        "  def back_propogation(self ,  output_error , learning_rate):\n",
        "    return self.activation_derivated(self.input) * output_error"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wphc1mFoZZXe"
      },
      "source": [
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def tanh_derivated(x):\n",
        "  return 1-np.tanh(x) ** 2\n",
        "\n",
        "#sigmoid\n",
        "def sigmoid(x):\n",
        "  return 1.0/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivated(x):\n",
        "  return sigmoid(x) * (1-sigmoid(x))\n",
        "\n",
        "\n",
        "#rectifire linear unit\n",
        "def relu(x):\n",
        "  print(x)\n",
        "  res = []\n",
        "  for i in x:\n",
        "    \n",
        "    y = [max(0,a) for a in i]\n",
        "    res.append(y)\n",
        "  y = np.array(res)\n",
        "  return y \n",
        "\n",
        "def relu_derivated(x):\n",
        "  res = []\n",
        "  for i in x:\n",
        "    \n",
        "    y = [1 if a> 0 else 0 for a in i]\n",
        "    res.append(y)\n",
        "  y = np.array(res)\n",
        "  return y\n",
        "\n",
        "#softmax\n",
        "def softmax(x):\n",
        "  return "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai95HPyUZsWP"
      },
      "source": [
        "#defining the lose\n",
        "\n",
        "def mse(y_true , y_pred):\n",
        "  return np.mean(np.power(y_true - y_pred , 2))\n",
        "\n",
        "def mse_derivated(y_true , y_pred):\n",
        "  return 2*(y_pred - y_true) / y_true.size"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_vLQIzdaOyL"
      },
      "source": [
        "#defning the network or model\n",
        "\n",
        "class model:\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "    self.loss = None\n",
        "    self.loss_derivated = None\n",
        "\n",
        "  #adding layer to the model\n",
        "  def add(self , layer):\n",
        "    self.layers.append(layer)\n",
        "\n",
        "  def setloss(self, loss , loss_derivated):\n",
        "    self.loss = loss\n",
        "    self.loss_derivated = loss_derivated\n",
        "\n",
        "  #predict the unknow data\n",
        "  def predict(self , Newinput):\n",
        "    samples = len(Newinput)\n",
        "    result = []\n",
        "    for i in range(samples):\n",
        "      output = Newinput[i]\n",
        "      \n",
        "      for layer in self.layers:\n",
        "        output = layer.forward_propogation(output)\n",
        "\n",
        "      result.append(output)\n",
        "    return result\n",
        "  \n",
        "  def fit(self , x_train , y_train , epoches , learning_rate):\n",
        "    sampels = len(x_train)\n",
        "    for i in range(epoches):\n",
        "      err = 0\n",
        "      for j in range(sampels):\n",
        "        output = x_train[j]\n",
        "        #print(output , j) \n",
        "        for layer in self.layers:\n",
        "          print(layer)\n",
        "          output = layer.forward_propogation(output)\n",
        "          print(output)\n",
        "        \n",
        "        #compute the loss\n",
        "        err += self.loss(y_train[j] , output)\n",
        "\n",
        "        #backpropogation\n",
        "        error = self.loss_derivated(y_train[j] , output)\n",
        "\n",
        "        #update the weights\n",
        "        for layer in reversed(self.layers):\n",
        "          error = layer.back_propogation(error , learning_rate)\n",
        "        \n",
        "    #calculate the average error and display that\n",
        "      err /= sampels\n",
        "      print('epoches..'+str(i)+'/'+str(epoches)+'-------'+'Error',err)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XbA3qhdph9D"
      },
      "source": [
        "#lets try with XOR operation to check it works fine\n",
        "X_train = np.array([[[0,0]] , [[0,1]] , [[1,0]] , [[1,1]]])\n",
        "\n",
        "y_train = np.array([[[0]] , [[1]] , [[1]] , [[0]]])\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNHVoHvPTar2"
      },
      "source": [
        "#binary classification\n",
        "(Xtrain , ytrain) , (Xtest,ytest) = mnist.load_data()\n",
        "#generating the binary dataset\n",
        "X_train , y_train ,X_test , y_test = [],[],[],[]\n",
        "for i in range(6000):\n",
        "  if ytrain[i] == 0 or ytrain[i] == 1:\n",
        "    X_train.append(Xtrain[i])\n",
        "    y_train.append(ytrain[i])\n",
        "for i in range(1000):\n",
        "  if ytest[i] == 0 or ytest[i] == 1:\n",
        "    X_test.append(Xtest[i])\n",
        "    y_test.append(ytest[i])\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "#preprocessing\n",
        "X_train = X_train.reshape(X_train.shape[0], 784, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 784, 1)\n",
        "\n",
        "y_train = to_categorical(y_train,num_classes=2)\n",
        "y_test = to_categorical(y_test,num_classes=2)\n",
        "\n",
        "#normalize\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8WoJ-MyV0OK",
        "outputId": "318caa3c-26d9-4190-ecfd-8d67175bdfe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1263, 784, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaISs2VRK5rq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "1a599a34-5bc6-4e8b-d531-6458323b8397"
      },
      "source": [
        "#build the network\n",
        "m = model()\n",
        "m.add(FClayer(784,100))\n",
        "m.add(ActivationLayer(relu,relu_derivated))\n",
        "\n",
        "m.add(FClayer(100,10))\n",
        "m.add(ActivationLayer(sigmoid,sigmoid_derivated))\n",
        "\n",
        "m.setloss(mse , mse_derivated)\n",
        "m.fit(X_train , y_train , epoches = 2 , learning_rate = 0.1)\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.FClayer object at 0x7f61a0b36a10>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-7a3b95131cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmse_derivated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepoches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-2f77edfd89ea>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, epoches, learning_rate)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propogation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-476906b4d6b7>\u001b[0m in \u001b[0;36mforward_propogation\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print('weights',self.weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print('bias',self.bias)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (784,1) and (784,100) not aligned: 1 (dim 1) != 784 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on2_ixp8L3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac41c6d-07f0-449b-b436-b4e40584a6a7"
      },
      "source": [
        "y_pred = model.predict(X_train)\n",
        "y_pred"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.26723028]]),\n",
              " array([[0.61908763]]),\n",
              " array([[0.575527]]),\n",
              " array([[0.65980984]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C2FjuwagTDF"
      },
      "source": [
        "#almost correct more epoches will bring better than this"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxHHGm-thAGw",
        "outputId": "b2024a4a-2ada-4826-e558-01edc7bd6b65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = [[ 0.1482825  ,-0.0291078 , -0.42258004]]\n",
        "res = []\n",
        "for i in x:\n",
        "  print(i)\n",
        "  y = [1 if a> 0 else 0 for a in i]\n",
        "  res.append(y)\n",
        "y = np.array(res)\n",
        "y"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1482825, -0.0291078, -0.42258004]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KOpWPAIJwbF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}