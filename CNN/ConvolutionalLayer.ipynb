{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalLayer",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/pavi-ninjaac/NuralNetwork_scratch/blob/main/CNN/ConvolutionalLayer.ipynb",
      "authorship_tag": "ABX9TyOCgYQcRbtGNGBqDIInZHQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavi-ninjaac/NuralNetwork_scratch/blob/main/CNN/ConvolutionalLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IpwmtBke1F9"
      },
      "source": [
        "# conolutional layer\r\n",
        "import numpy as np"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUignDQe8Vv"
      },
      "source": [
        "class con2D:\r\n",
        "  def __init__(self, filter , kernal_size, img_channel,strides = (1,1)):\r\n",
        "    self.filter = None\r\n",
        "    self.bias = None\r\n",
        "    self.input = None\r\n",
        "    \"\"\"Convolute the image with the filter and strids\"\"\"\r\n",
        "    \r\n",
        "    \r\n",
        "    f_channel = img_channel               #filter channel must match with the image channel\r\n",
        "    self.no_filters = filter                   # number of filters\r\n",
        "    f_dim , _ = kernal_size\r\n",
        "    self.f_dim =  f_dim              # get the filter size\r\n",
        "    self.strides , _ = strides\r\n",
        "    f_size = (self.no_filters , f_channel , f_dim , f_dim) # get the strides dimentions\r\n",
        "\r\n",
        "    #initialize the filter\r\n",
        "    \"\"\" Initalize the filter with the noraml distribution with the standard deviation inversely proportional the square root of the number of units\"\"\"\r\n",
        "    sdv = 1.0 / np.sqrt(np.prod(f_size))\r\n",
        "    self.filter = np.random.normal(loc = 0, scale = sdv, size = f_size)\r\n",
        "    #self.filter = np.array([[[1,0,1] , [2,1,1] , [0,1,2]]])\r\n",
        "    self.bias = np.zeros((self.no_filters , 1)) # each for the one filters    \r\n",
        "\r\n",
        "  \r\n",
        "  #forward propogaton\r\n",
        "  def forward_propogation(self, image):\r\n",
        "    self.input = image\r\n",
        "    #print(image.shape)\r\n",
        "    (img_channel , input_dim , _ ) = image.shape #input dimensions channel first dimention \r\n",
        "    \r\n",
        "    #calculate the output dimension, so according to that i can create the empty array to store value\r\n",
        "    out_dim = int(((input_dim - self.f_dim) / self.strides) + 1)\r\n",
        "    \r\n",
        "    #create the empty array with output dimetions\r\n",
        "    self.output = np.zeros((1 , out_dim, out_dim )) #syntax np.zeros(channel , row , col)\r\n",
        "    for curr_filter in range(self.no_filters): # for loop over the number of filters\r\n",
        "      curr_y = out_y =0\r\n",
        "      \r\n",
        "      #move vertically over the image\r\n",
        "      while (curr_y + self.f_dim) <= input_dim:\r\n",
        "        curr_x = out_x = 0\r\n",
        "        #move horizondally\r\n",
        "        while (curr_x + self.f_dim) <= input_dim:\r\n",
        "          \r\n",
        "          \"\"\"perform convolution operation on the image\"\"\"\r\n",
        "          self.output[curr_filter , curr_y , curr_x] = np.sum(self.filter[curr_filter] * image[: , curr_y : curr_y + self.f_dim , curr_x : curr_x + self.f_dim]) #+ self.bias[curr_filter]\r\n",
        "\r\n",
        "          curr_x += self.strides\r\n",
        "          out_x +=1\r\n",
        "        curr_y += self.strides\r\n",
        "        out_y += 1\r\n",
        "    #print(self.output)\r\n",
        "    return self.output\r\n",
        "\r\n",
        "  def back_propogation(self , error_input , learning_rate):\r\n",
        "      \"\"\"update the filter \"\"\" # gonna use the self.no_filters and self.f_dim\r\n",
        "      image_channel , img_dim , _ = self.input.shape\r\n",
        "\r\n",
        "      #initialize the derivations by creating zero array\r\n",
        "      dout = np.zeros(self.input.shape)\r\n",
        "      d_filter = np.zeros(self.filter.shape)\r\n",
        "      d_bias = np.zeros(self.bias.shape)\r\n",
        "      for curr_filter in range(self.no_filters): # for loop over the number of filters\r\n",
        "        curr_y = out_y =0\r\n",
        "      \r\n",
        "        #move vertically over the image\r\n",
        "        while (curr_y + self.f_dim) <= img_dim:\r\n",
        "          curr_x = out_x = 0\r\n",
        "          #move horizondally\r\n",
        "          while (curr_x + self.f_dim) <= img_dim:\r\n",
        "          \r\n",
        "            \"\"\"loss gradiant on filters\"\"\"\r\n",
        "            #update the filter\r\n",
        "            #print('filter' , self.filter)\r\n",
        "            #print('zero filter' , d_filter)\r\n",
        "            d_filter[curr_filter] +=  error_input[curr_filter , out_y , out_x] * self.input[: , curr_y : curr_y + self.f_dim , curr_x : curr_x + self.f_dim]\r\n",
        "\r\n",
        "            #gradiant of the input \r\n",
        "            dout[: , curr_y : curr_y + self.f_dim , curr_x : curr_x + self.f_dim] += error_input[curr_filter , out_y , out_x] * self.filter[curr_filter]\r\n",
        "\r\n",
        "            \r\n",
        "            curr_x += self.strides\r\n",
        "            out_x +=1\r\n",
        "          curr_y += self.strides\r\n",
        "          out_y += 1\r\n",
        "        d_bias[curr_filter] = np.sum(error_input[curr_filter])\r\n",
        "    #update the weights\r\n",
        "        self.filter = d_filter\r\n",
        "        self.bias = d_bias\r\n",
        "      #print(dout)\r\n",
        "      return dout\r\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVoaFlOtZHF6"
      },
      "source": [
        "class MaxPooling2D(con2D):\r\n",
        "  def __init__(self , pool_size = 1, strides=1):\r\n",
        "    self.pool_size = pool_size #getting the kernal size for pooling the layer out\r\n",
        "    self.strides = strides\r\n",
        "    self.image = None\r\n",
        "    \r\n",
        "  def forward_propogation(self , image):\r\n",
        "\r\n",
        "    \"\"\" downsample of the image using the kernal size and strides\"\"\"\r\n",
        "    self.image = image\r\n",
        "    img_channel , h_prev , w_prev  = image.shape    # shape of the image\r\n",
        "    # calculate output dimensions after the maxpooling operation.\r\n",
        "    h = int((h_prev - self.pool_size)/self.strides)+1 \r\n",
        "    w = int((w_prev - self.pool_size)/self.strides)+1\r\n",
        "    \r\n",
        "    # create a matrix to hold the values of the maxpooling operation.\r\n",
        "    self.output = np.zeros((img_channel, h, w))\r\n",
        "    # slide the window over every part of the image using stride s. Take the maximum value at each step.\r\n",
        "    for i in range(img_channel):\r\n",
        "        curr_y = out_y = 0\r\n",
        "        # slide the max pooling window vertically across the image\r\n",
        "        while curr_y + self.pool_size <= h_prev:\r\n",
        "            curr_x = out_x = 0\r\n",
        "            # slide the max pooling window horizontally across the image\r\n",
        "            while curr_x + self.pool_size <= w_prev:\r\n",
        "                # choose the maximum value within the window at each step and store it to the output matrix\r\n",
        "                self.output[i, out_y, out_x] = np.max(image[i, curr_y:curr_y+self.pool_size, curr_x:curr_x+self.pool_size])\r\n",
        "                curr_x += self.strides\r\n",
        "                out_x += 1\r\n",
        "            curr_y += self.strides\r\n",
        "            out_y += 1\r\n",
        "    #print(self.output)\r\n",
        "    return self.output\r\n",
        "\r\n",
        "  def get_max_index(self , arr):\r\n",
        "      \"\"\"return the index of the maximum value in the array\"\"\"\r\n",
        "      flat_index = np.nanargmax(arr)\r\n",
        "      idex = np.unravel_index(flat_index , arr.shape)\r\n",
        "      return idex\r\n",
        "\r\n",
        "\r\n",
        "  def back_propogation(self, output , learning_rate):\r\n",
        "      \"\"\"put the max value in it's old position ,,,fill remaining with zeros\"\"\"\r\n",
        "      img_channel , img_dim , _  = self.image.shape\r\n",
        "\r\n",
        "      #create an zero value array with the original image size\r\n",
        "      dout = np.zeros(self.image.shape)\r\n",
        "      # slide the window over every part of the image using stride s. Take the maximum value at each step.\r\n",
        "      for cuur_channel in range(img_channel):\r\n",
        "        curr_y = out_y = 0\r\n",
        "        # slide the max pooling window vertically across the image\r\n",
        "        while curr_y + self.pool_size <= img_dim:\r\n",
        "            curr_x = out_x = 0\r\n",
        "            # slide the max pooling window horizontally across the image\r\n",
        "            while curr_x + self.pool_size <= img_dim:\r\n",
        "              #obtain the index of the maximum value in that window size\r\n",
        "              a,b = self.get_max_index(self.image[cuur_channel , curr_y:curr_y+self.pool_size, curr_x:curr_x+self.pool_size])\r\n",
        "              dout[cuur_channel , curr_y+a , curr_x+b] = output[cuur_channel , curr_y , curr_x]\r\n",
        "\r\n",
        "              curr_x += self.strides\r\n",
        "              out_x += 1\r\n",
        "            curr_y += self.strides\r\n",
        "            curr_y += 1\r\n",
        "      #print(dout)\r\n",
        "      return dout\r\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKZCutOkcabM"
      },
      "source": [
        "class Flatten(con2D):\r\n",
        "  \"\"\" get the strignt single channel fully connet layer \"\"\"\r\n",
        "  def __init__(self):\r\n",
        "    self.image = None\r\n",
        "    self.flatten_image = None\r\n",
        "    \r\n",
        "  def forward_propogation(self , image):\r\n",
        "    #store the image  size to use in the backpropogation\r\n",
        "    self.image = image\r\n",
        "    image_channel , input_dim , _ = image.shape\r\n",
        "    a = image.flatten()  #flatten the image \r\n",
        "    self.flatten_image = np.array([a]) #make it to 2D\r\n",
        "    #print(self.flatten_image)\r\n",
        "    #print('flatten image shape for further use',self.flatten_image.shape) \r\n",
        "    return self.flatten_image \r\n",
        "\r\n",
        "  def back_propogation(self , output , learning_rate):\r\n",
        "    output = output.reshape(self.image.shape)\r\n",
        "    #print(output)\r\n",
        "    return output  # mae it into the original size\r\n",
        "    \r\n",
        "      "
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ4RKj2mdaGF"
      },
      "source": [
        "class FClayer(Flatten):\r\n",
        "  def __init__(self , input_size , output_size):\r\n",
        "    self.input = None\r\n",
        "    self.input_size = input_size\r\n",
        "    self.output = None\r\n",
        "    # initialize the weights using the normal distribution\r\n",
        "    self.weights = np.random.rand(self.input_size , output_size) - 0.5\r\n",
        "    self.bias =  np.random.rand(1,output_size) - 0.5 \r\n",
        "  \r\n",
        "  def forward_propogation(self , input):\r\n",
        "    self.input = input\r\n",
        "    self.output = np.dot(self.input , self.weights) + self.bias\r\n",
        "    print(self.output)\r\n",
        "    return self.output\r\n",
        "  \r\n",
        "  def back_propogation(self, output_error , learning_rate):\r\n",
        "    #print('coming gradiant' , output_error)\r\n",
        "    #print(' weight' , self.weights)\r\n",
        "    #print('back input ',self.input)\r\n",
        "    #print('bias',self.bias)\r\n",
        "    #print('finding the input error')\r\n",
        "    #print('the weight transpose' , self.weights.T)\r\n",
        "    #print('error',output_error ,'*' ,self.weights.T )\r\n",
        "    input_error = np.dot(output_error , self.weights.T)  #dE/dX = W.T * dE / dY\r\n",
        "    \r\n",
        "    \r\n",
        "    #print('input transpose',self.input.T)\r\n",
        "    weights_error = np.dot(self.input.T , output_error) #dE/dW = X.T * dE / dY\r\n",
        "    bias_error = output_error                           #dE/dB =  dE / dY\r\n",
        "    #update the weights and bias\r\n",
        "    self.weights -= learning_rate *  weights_error\r\n",
        "    self.bias -= learning_rate * bias_error\r\n",
        "    #print(input_error)\r\n",
        "    return input_error\r\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bQtsIVFXBzv"
      },
      "source": [
        "def softmax_funtion(output):\r\n",
        "  \"\"\" pass the raw predicted data to the activation function to get the probability\"\"\"\r\n",
        "  output = np.array(output , dtype = np.float128)\r\n",
        "  print('softmax function',output.dtype)\r\n",
        "  output = np.exp(output) # exponent the predicted output\r\n",
        "  return output / np.sum(output)\r\n",
        "\r\n",
        "def softmax_derivated(loss_derivated_error):\r\n",
        "  return loss_derivated_error\r\n"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHWBhiT-XT3z"
      },
      "source": [
        "def catogarical_cross_entropy(label , prob):\r\n",
        "  \"\"\" calculate the categorical cross entropy loss\"\"\"\r\n",
        "  return -np.sum(label * np.log(prob)) #multiply the output with the log of probability\r\n",
        "\r\n",
        "def catogarical_cross_entropy_derivated(label , prob):\r\n",
        "  loss_derivated_error =  prob - label \r\n",
        "  print('loss derivated',loss_derivated_error)\r\n",
        "  return loss_derivated_error"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnUTA81OVPh1"
      },
      "source": [
        "class softmax(FClayer):\r\n",
        "  def __init__(self, actvation = softmax_funtion , activation_derivated = softmax_derivated): #default parameter setting\r\n",
        "    self.actvation = actvation #show the activation from the outside class\r\n",
        "    self.activation_derivated = activation_derivated\r\n",
        "\r\n",
        "  def forward_propogation(self , input_data):\r\n",
        "    self.input = input_data \r\n",
        "    self.output = self.actvation(self.input)\r\n",
        "    #print('soft max activation',self.output)\r\n",
        "    return self.output\r\n",
        "\r\n",
        "  def back_propogation(self ,  output_error , learning_rate):\r\n",
        "    return self.activation_derivated(self.input) * output_error"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxpXaBr2ZDgW"
      },
      "source": [
        "class Relu(con2D):\r\n",
        "  \"\"\" pass through the relu activation function\"\"\"\r\n",
        "  def __init__(self):\r\n",
        "    self.output = None\r\n",
        "\r\n",
        "  def forward_propogation(self,input):\r\n",
        "    input[input<=0] = 0\r\n",
        "    self.output = input\r\n",
        "    #print(self.output)\r\n",
        "    return self.output\r\n",
        "  \r\n",
        "  def back_propogation(self,output_error , learning_rate):\r\n",
        "    output_error[output_error<=0] = 0\r\n",
        "    return output_error\r\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je7KVBmaF8oC"
      },
      "source": [
        "class network:\r\n",
        "  def __init__(self):\r\n",
        "    self.layers = []\r\n",
        "\r\n",
        "  #add the layer in the model\r\n",
        "  def add(self , layer):\r\n",
        "    self.layers.append(layer)\r\n",
        "  #set the loss function to use it out\r\n",
        "  def setloss(self, loss , loss_derivated):\r\n",
        "    self.loss = loss\r\n",
        "    self.loss_derivated = loss_derivated\r\n",
        "\r\n",
        "  def fit(self , x_train ,  y_train , epoches ,learning_rate):\r\n",
        "    sampels = len(x_train)\r\n",
        "    #loop over for epoches\r\n",
        "    for i in range(epoches):\r\n",
        "      err = 0\r\n",
        "      for j in range(sampels):\r\n",
        "        print('sample' , j)\r\n",
        "        output = x_train[j]  #loop our the training image\r\n",
        "        for layer in self.layers:\r\n",
        "          print(layer)\r\n",
        "          output = layer.forward_propogation(output)\r\n",
        "          \r\n",
        "        print(output.dtype)\r\n",
        "        print('output of softmax',output)\r\n",
        "          \r\n",
        "\r\n",
        "        #compute the loss\r\n",
        "                \r\n",
        "        err += self.loss(y_train[j] , output)\r\n",
        "        print('loss ',err)\r\n",
        "        #backpropogation\r\n",
        "        error = self.loss_derivated(y_train[j] , output)\r\n",
        "        \r\n",
        "        #update the weights\r\n",
        "        print('backporopogation stated')\r\n",
        "        for layer in reversed(self.layers):\r\n",
        "          #print('back',layer)\r\n",
        "          error = layer.back_propogation(error , learning_rate)\r\n",
        "          \r\n",
        "      #displae the error and epoches for the reference\r\n",
        "      err/=sampels\r\n",
        "      print('epoches..'+str(i)+'/'+str(epoches)+'-------'+'Error',err)\r\n",
        "    \r\n",
        "\r\n"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BIiq9PAqGVz"
      },
      "source": [
        "# Check it with one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI_1_WYMqF9V"
      },
      "source": [
        "#import packages\r\n",
        "import pandas as pd\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB_Rx_O4tara",
        "outputId": "520c4da9-85e5-4a29-e828-d742cb2b96d9"
      },
      "source": [
        "#load the image dataset\r\n",
        "(X_train , y_train ), (X_test , y_test )= mnist.load_data()\r\n",
        "print(\"shape of the X_train \", X_train.shape)\r\n",
        "print(\"shape of the X_train \", y_train.shape)\r\n",
        "print(\"shape of the X_train \", X_test.shape)\r\n",
        "print(\"shape of the X_train \", y_test.shape)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the X_train  (60000, 28, 28)\n",
            "shape of the X_train  (60000,)\n",
            "shape of the X_train  (10000, 28, 28)\n",
            "shape of the X_train  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZTQQ8X15jc_"
      },
      "source": [
        "# Clean the datsset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dgrf3xc5ihD",
        "outputId": "ffcfb757-2d5e-4b49-9e72-8480fe26b938"
      },
      "source": [
        "X_train =   X_train.reshape(X_train.shape[0] , 1 , 28 , 28)\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "#X_train /= 255.0\r\n",
        "\r\n",
        "#clean the test dataset\r\n",
        "X_test =   X_test.reshape(X_test.shape[0] , 1 , 28 , 28)\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "#X_test /= 255.0\r\n",
        "#print(X_train[0])\r\n",
        "#one hot encode the output\r\n",
        "print(y_train[0])\r\n",
        "y_train = np_utils.to_categorical(y_train)\r\n",
        "print(y_train[0])\r\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IP-tHuN6qTja",
        "outputId": "0336f407-a01d-41c7-ee04-1e4aad27b654"
      },
      "source": [
        "#@title Default title text\n",
        "car_path = '/content/drive/MyDrive/Colab Notebooks/dataFiles/DNA_Genome_Analysis_covid19/car.png'\n",
        "car_img = image.load_img(car_path , target_size = (28,28))\n",
        "car_arr = image.img_to_array(car_img)\n",
        "plt.imshow(car_img)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efd9a105810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtEJ1g6OHtBm"
      },
      "source": [
        "#build the model \r\n",
        "model = network()\r\n",
        "model.add(con2D(filter = 1 , kernal_size =(3,3) , strides = (1,1) , img_channel =1))\r\n",
        "model.add(Relu())\r\n",
        "model.add(MaxPooling2D(pool_size = 2))\r\n",
        "model.add(Relu())\r\n",
        "model.add(Flatten())\r\n",
        "model.add(FClayer(625,128))\r\n",
        "model.add(FClayer(128,10))\r\n",
        "model.add(softmax())"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MAc1cZ1GMI70",
        "outputId": "d9c8a735-9cff-4490-a077-2d638330095f"
      },
      "source": [
        "#i = np.array([[[[1,2,1,0,1] , [2,1,1,2,1] , [3,2,1,0,0] , [0,1,2,3,1] , [2,1,1,0,2]]]])\r\n",
        "#print(i.shape)\r\n",
        "#set the loss to compute the loss\r\n",
        "model.setloss(loss = catogarical_cross_entropy , loss_derivated = catogarical_cross_entropy_derivated)\r\n",
        "model.fit(X_train ,y_train ,10 , learning_rate = 0.01)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample 0\n",
            "<__main__.con2D object at 0x7efd8b94b810>\n",
            "<__main__.Relu object at 0x7efd8b94b450>\n",
            "<__main__.MaxPooling2D object at 0x7efd8b94bdd0>\n",
            "<__main__.Relu object at 0x7efd8b94bb50>\n",
            "<__main__.Flatten object at 0x7efd8b94b950>\n",
            "<__main__.FClayer object at 0x7efd8b94b090>\n",
            "[[ 2.16721945e+02 -1.83201366e+02 -2.47965072e+02 -5.72275992e+01\n",
            "   2.48282013e+02  1.99598971e+02 -8.01010351e+00  1.89676175e+02\n",
            "   3.19774589e+02 -1.49449005e+02 -8.81119901e+01  1.87619872e+02\n",
            "  -1.26082229e+02 -7.82477131e+01  1.01403436e+02  7.32549382e+01\n",
            "   3.47124644e+02 -2.04112538e+02  1.77771945e+01 -1.23555672e+02\n",
            "   4.34876480e+02 -3.22907942e+02  2.48631181e+02 -1.55845181e+02\n",
            "  -4.46850331e+01  7.96112917e+01  7.65886246e+01 -3.61917456e+02\n",
            "   2.48537297e+02 -2.33830344e+02  3.62367518e+01  2.31488166e+02\n",
            "   1.52767470e+02 -1.75274503e+02 -3.46247099e+02 -2.47780378e+02\n",
            "  -2.01107849e+02 -7.27371713e+01  3.05842135e+01  2.12375559e+02\n",
            "   2.61645266e+02 -2.75770295e+02 -2.46625095e+02 -1.68300543e+02\n",
            "  -5.72860568e+01 -5.34912295e+01 -5.43184330e+01  3.72828733e+02\n",
            "  -1.08765266e+02  1.76038627e+02 -2.94979253e+02  2.44396750e+02\n",
            "  -2.25722847e+02  9.22001266e+01  1.88277028e+01  3.00235591e+02\n",
            "   4.04481783e+01 -5.19543336e+01 -6.93145720e+01 -1.43170226e+02\n",
            "  -4.80974417e+01  1.45980728e+02 -4.08922510e+02 -1.95692523e+02\n",
            "  -6.53579499e+01 -9.76358242e+01 -1.99791838e+02 -2.51270565e+02\n",
            "  -3.05817660e+02 -1.31627909e+02 -1.44585396e+02 -2.24045239e+02\n",
            "   1.27177741e+02 -1.53978317e+02 -2.31970316e+02 -1.05811218e+02\n",
            "  -2.27330799e+02  1.53592490e+02 -7.98547682e+01  1.93311234e+02\n",
            "   2.67552959e+02  2.42357779e+02  2.07724821e+02 -9.54697827e+01\n",
            "  -4.38925262e+02 -3.42169151e+02 -2.02006337e+02  1.41017051e+01\n",
            "   2.66959713e+01 -3.79205352e+01 -1.31876923e+01 -5.02909143e+01\n",
            "  -3.23269347e+02 -4.11300503e+02  3.11078517e+02  3.05026444e+02\n",
            "   2.29343370e+02  1.49084379e+00 -2.86659294e+02  1.75964548e+01\n",
            "   7.08852304e+01 -2.28493440e+01 -3.99984906e+02 -1.89398681e+02\n",
            "   4.12891574e+02  1.80301730e+02 -1.00293378e+02  3.09535327e+02\n",
            "   4.46562728e+02  2.62742487e+02 -1.01370700e+02 -8.80495783e+01\n",
            "   1.70563583e+02 -2.31056183e+00 -3.54552407e+02  8.59406128e+01\n",
            "  -2.39357710e+02 -3.36495900e+01 -2.31358634e+02 -1.43541468e-01\n",
            "  -7.23765982e+01 -3.32001173e+02 -1.79065553e+02 -8.81557931e+01\n",
            "   9.56088789e+01 -2.82354170e+01  5.29163499e+01 -1.89957188e+01]]\n",
            "<__main__.FClayer object at 0x7efd8b94b3d0>\n",
            "[[  282.69722164  -525.0578318     -8.52680459 -1158.92526836\n",
            "   -494.55425334   -97.84592673   390.24234135   908.41371128\n",
            "  -2558.2041104    -26.83468046]]\n",
            "<__main__.softmax object at 0x7efd8b835e90>\n",
            "softmax function float128\n",
            "float128\n",
            "output of softmax [[1.79796533e-0272 2.82630400e-0623 5.99506258e-0399 1.46584793e-0898\n",
            "  4.99752159e-0610 9.70491750e-0438 9.14183457e-0226 1.00000000e+0000\n",
            "  2.93095518e-1506 6.71095394e-0407]]\n",
            "loss  1006.2596380156080613\n",
            "loss derivated [[-1.79796533e-0272 -2.82630400e-0623 -5.99506258e-0399 -1.46584793e-0898\n",
            "  -4.99752159e-0610  1.00000000e+0000 -9.14183457e-0226 -1.00000000e+0000\n",
            "  -2.93095518e-1506 -6.71095394e-0407]]\n",
            "backporopogation stated\n",
            "sample 1\n",
            "<__main__.con2D object at 0x7efd8b94b810>\n",
            "<__main__.Relu object at 0x7efd8b94b450>\n",
            "<__main__.MaxPooling2D object at 0x7efd8b94bdd0>\n",
            "<__main__.Relu object at 0x7efd8b94bb50>\n",
            "<__main__.Flatten object at 0x7efd8b94b950>\n",
            "<__main__.FClayer object at 0x7efd8b94b090>\n",
            "[[-4.60377717e+13 -4.90442243e+13 -3.09951353e+13 -5.74732075e+13\n",
            "  -4.37773415e+13  4.75001131e+13  3.74276644e+12  1.17488155e+14\n",
            "   6.19781021e+13 -5.95402975e+13  1.02416140e+14 -8.91138012e+13\n",
            "  -9.70163483e+13  1.31298122e+13  3.92833702e+13 -8.95657346e+12\n",
            "   6.98522492e+13  8.84041057e+13 -7.65528620e+13 -9.94820611e+13\n",
            "   7.49133055e+11  9.22460536e+13  3.18799707e+13  8.39768252e+13\n",
            "  -6.48809352e+13 -2.11379955e+13  7.41090035e+13  9.79276565e+13\n",
            "   6.15534722e+13 -4.58972854e+13 -1.11215248e+14 -4.03412435e+13\n",
            "   1.04693865e+14  9.19043872e+13  8.26272715e+13 -5.77454790e+13\n",
            "   1.03229543e+14  3.13132422e+13  7.12759039e+13 -8.47562658e+13\n",
            "   2.08490987e+13 -9.18648125e+12  6.85998987e+12 -5.13403348e+13\n",
            "   7.12032698e+13  1.80212569e+13 -4.83848686e+13  5.31914940e+13\n",
            "   3.01838929e+13 -9.66611001e+12 -7.34902769e+13 -8.37973021e+13\n",
            "  -3.12840091e+13  1.26381402e+14  5.74439194e+13  1.17913679e+14\n",
            "   8.12686605e+13  1.03473832e+14  7.31673972e+13 -4.72155856e+13\n",
            "   9.76537226e+13  2.54337131e+13  7.24582023e+13  6.41804105e+13\n",
            "   6.06377050e+13 -9.14416766e+13  2.87339097e+13 -6.42237839e+13\n",
            "   1.21274738e+13  8.66987041e+12 -8.37056968e+13 -2.35809849e+13\n",
            "  -5.83504608e+13 -1.19918259e+13 -1.25697705e+13 -4.86368021e+13\n",
            "  -8.69559472e+13 -1.11555924e+14 -5.27186870e+13 -6.81245946e+13\n",
            "   6.02513226e+13  1.24159126e+14  3.09734640e+13  3.20932225e+13\n",
            "  -8.83680027e+13 -7.47583205e+13 -6.23162352e+13 -3.26034013e+13\n",
            "  -7.30802754e+13 -7.67894952e+13 -3.35569951e+13 -8.88915356e+13\n",
            "   2.44482605e+13 -1.12945228e+14  1.13041085e+14 -5.78188144e+13\n",
            "  -6.67746052e+13  2.59862612e+13  7.22898774e+13 -2.26531621e+13\n",
            "   7.35143397e+13 -2.57428618e+13 -1.22695760e+14 -7.44357397e+13\n",
            "  -2.66206574e+13 -7.56244630e+13  8.42986107e+13  1.37533027e+12\n",
            "   5.10602139e+13 -8.44683889e+13 -9.71344176e+12  3.60668782e+13\n",
            "  -9.51860015e+13  3.08807352e+13 -1.44197427e+12  3.10678317e+13\n",
            "  -5.52091521e+13  1.45071759e+13 -3.60545946e+12 -1.06909829e+14\n",
            "  -9.65028966e+13  2.67858754e+13 -7.12507453e+13 -5.90182773e+12\n",
            "   8.71503386e+12  1.02809346e+14 -5.31124991e+13  1.19683030e+14]]\n",
            "<__main__.FClayer object at 0x7efd8b94b3d0>\n",
            "[[ 2.97835512e+12  7.58562355e+13  1.11089376e+14 -1.27316748e+14\n",
            "   7.12270483e+13  2.12716891e+17  1.00919816e+14  1.97355913e+18\n",
            "  -6.33095201e+13  5.20412299e+13]]\n",
            "<__main__.softmax object at 0x7efd8b835e90>\n",
            "softmax function float128\n",
            "float128\n",
            "output of softmax [[nan nan nan  0. nan nan nan nan  0. nan]]\n",
            "loss  nan\n",
            "loss derivated [[nan nan nan  0. nan nan nan nan  0. nan]]\n",
            "backporopogation stated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "sample 2\n",
            "<__main__.con2D object at 0x7efd8b94b810>\n",
            "<__main__.Relu object at 0x7efd8b94b450>\n",
            "<__main__.MaxPooling2D object at 0x7efd8b94bdd0>\n",
            "<__main__.Relu object at 0x7efd8b94bb50>\n",
            "<__main__.Flatten object at 0x7efd8b94b950>\n",
            "<__main__.FClayer object at 0x7efd8b94b090>\n",
            "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan]]\n",
            "<__main__.FClayer object at 0x7efd8b94b3d0>\n",
            "[[nan nan nan nan nan nan nan nan nan nan]]\n",
            "<__main__.softmax object at 0x7efd8b835e90>\n",
            "softmax function float128\n",
            "float128\n",
            "output of softmax [[nan nan nan nan nan nan nan nan nan nan]]\n",
            "loss  nan\n",
            "loss derivated [[nan nan nan nan nan nan nan nan nan nan]]\n",
            "backporopogation stated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-251-94fc7b35e29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#set the loss to compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatogarical_cross_entropy\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloss_derivated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatogarical_cross_entropy_derivated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-249-3c2e62876cde>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, epoches, learning_rate)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0;31m#print('back',layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m           \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propogation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0;31m#displae the error and epoches for the reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-143-e354e226bd24>\u001b[0m in \u001b[0;36mback_propogation\u001b[0;34m(self, output, learning_rate)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mcurr_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mimg_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m               \u001b[0;31m#obtain the index of the maximum value in that window size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m               \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcuur_channel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcurr_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurr_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m               \u001b[0mdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcuur_channel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcurr_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcurr_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcuur_channel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcurr_y\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcurr_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-143-e354e226bd24>\u001b[0m in \u001b[0;36mget_max_index\u001b[0;34m(self, arr)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_max_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;34m\"\"\"return the index of the maximum value in the array\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mflat_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0midex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_index\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanargmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanargmax\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All-NaN slice encountered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All-NaN slice encountered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpvgvIc-kQrb"
      },
      "source": [
        "s = np.array([[[1,0,1] , [2,1,1] , [0,1,2]]])\r\n",
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPCfdrQShnAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d637c706-77db-4ff7-ee2c-ec5ceaeb9a7d"
      },
      "source": [
        "n = np.array([[ 1889.1599303 ,   309.33289731 ,  152.73517451 ,-1600.86077456,\r\n",
        "   2505.15245823  , 749.31314978 , 1166.17901765 ,-4494.43938188,\r\n",
        "   1976.19386057, -2421.32088513]])\r\n",
        "\r\n",
        "\r\n",
        "for i in range(len(n)):\r\n",
        "  n[i] = np.exp(n[i]) \r\n",
        "print(n)\r\n",
        "sum = np.sum(n) \r\n",
        "print(sum) \r\n",
        "for i in range(len(n)):\r\n",
        "  print(n[i])\r\n",
        "  n[i] = (n[i] / sum )\r\n",
        "print(sum , n)\r\n",
        "\r\n",
        "np.sum(n)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[            inf 2.19568671e+134 2.14804553e+066 0.00000000e+000\n",
            "              inf             inf             inf 0.00000000e+000\n",
            "              inf 0.00000000e+000]]\n",
            "inf\n",
            "[            inf 2.19568671e+134 2.14804553e+066 0.00000000e+000\n",
            "             inf             inf             inf 0.00000000e+000\n",
            "             inf 0.00000000e+000]\n",
            "inf [[nan  0.  0.  0. nan nan nan  0. nan  0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdmN0b7pAe7u",
        "outputId": "fac22b9d-d0b3-496e-abe6-d405a747138d"
      },
      "source": [
        "301.95428447325344/520.2942363539252"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5803529298907165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmjpskyVA4Mh",
        "outputId": "2de1a77b-bc83-4c4e-b8d6-72fb3f025210"
      },
      "source": [
        "np.exp(5270.61915528)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgGtMYLSM2GU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}